{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this challenge is to design and build a predictive model capable of accurately determining the probability of an individual having heart disease. The focus is on leveraging machine learning techniques to create a model that can analyze relevant features and provide reliable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split,KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.read_csv(\"Train Dataset .csv\")\n",
    "test_data = pd.read_csv(\"Test Dataset.csv\")\n",
    "var = pd.read_csv(\"Variable_Definitions.csv\") \n",
    "sub = pd.read_csv(\"Sample Submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16167</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11275</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13251</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19921</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11293</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>419</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Age  Sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak   \n",
       "0  16167   33    0   1       158   205    1        0      154      0      1.5  \\\n",
       "1  11275   53    1   2       198   154    0        1      104      0      0.8   \n",
       "2  13251   37    1   2       101   202    1        0      155      0      2.1   \n",
       "3  19921   75    0   0       113   306    1        2       88      1      4.9   \n",
       "4  11293   35    1   2       139   419    1        1      166      1      0.9   \n",
       "\n",
       "   slope  ca  thal  target  \n",
       "0      1   4     1       1  \n",
       "1      2   1     0       0  \n",
       "2      1   3     1       1  \n",
       "3      0   2     2       1  \n",
       "4      2   4     0       1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16501</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>495</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10444</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14288</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>558</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10409</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17330</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak   \n",
       "0  16501   70    1   0       163   495    0        2      170      1      2.0  \\\n",
       "1  10444   61    1   0       131   238    0        2       74      1      4.9   \n",
       "2  14288   53    1   0        95   558    1        1       73      1      0.7   \n",
       "3  10409   37    0   1       178   287    0        1      192      1      5.7   \n",
       "4  17330   35    0   3       104   281    0        0      122      0      1.3   \n",
       "\n",
       "   slope  ca  thal  \n",
       "0      1   0     1  \n",
       "1      2   2     2  \n",
       "2      1   1     0  \n",
       "3      1   0     0  \n",
       "4      1   4     3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "      <td>7303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15021.535396</td>\n",
       "      <td>53.172669</td>\n",
       "      <td>0.499658</td>\n",
       "      <td>1.502533</td>\n",
       "      <td>147.447487</td>\n",
       "      <td>342.805970</td>\n",
       "      <td>0.493085</td>\n",
       "      <td>1.013008</td>\n",
       "      <td>136.506093</td>\n",
       "      <td>0.503218</td>\n",
       "      <td>3.129851</td>\n",
       "      <td>0.991510</td>\n",
       "      <td>2.019033</td>\n",
       "      <td>1.502259</td>\n",
       "      <td>0.813501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.026080</td>\n",
       "      <td>14.185970</td>\n",
       "      <td>0.500034</td>\n",
       "      <td>1.115594</td>\n",
       "      <td>31.099538</td>\n",
       "      <td>127.291998</td>\n",
       "      <td>0.499986</td>\n",
       "      <td>0.815806</td>\n",
       "      <td>38.141966</td>\n",
       "      <td>0.500024</td>\n",
       "      <td>1.791160</td>\n",
       "      <td>0.817291</td>\n",
       "      <td>1.410546</td>\n",
       "      <td>1.113137</td>\n",
       "      <td>0.389535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10001.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12521.500000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15054.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17513.500000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19998.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id          Age          Sex           cp     trestbps   \n",
       "count   7303.000000  7303.000000  7303.000000  7303.000000  7303.000000  \\\n",
       "mean   15021.535396    53.172669     0.499658     1.502533   147.447487   \n",
       "std     2886.026080    14.185970     0.500034     1.115594    31.099538   \n",
       "min    10001.000000    29.000000     0.000000     0.000000    94.000000   \n",
       "25%    12521.500000    41.000000     0.000000     1.000000   120.000000   \n",
       "50%    15054.000000    53.000000     0.000000     1.000000   148.000000   \n",
       "75%    17513.500000    65.000000     1.000000     3.000000   174.000000   \n",
       "max    19998.000000    77.000000     1.000000     3.000000   200.000000   \n",
       "\n",
       "              chol          fbs      restecg      thalach        exang   \n",
       "count  7303.000000  7303.000000  7303.000000  7303.000000  7303.000000  \\\n",
       "mean    342.805970     0.493085     1.013008   136.506093     0.503218   \n",
       "std     127.291998     0.499986     0.815806    38.141966     0.500024   \n",
       "min     126.000000     0.000000     0.000000    71.000000     0.000000   \n",
       "25%     231.000000     0.000000     0.000000   104.000000     0.000000   \n",
       "50%     341.000000     0.000000     1.000000   137.000000     1.000000   \n",
       "75%     450.000000     1.000000     2.000000   170.000000     1.000000   \n",
       "max     564.000000     1.000000     2.000000   202.000000     1.000000   \n",
       "\n",
       "           oldpeak        slope           ca         thal       target  \n",
       "count  7303.000000  7303.000000  7303.000000  7303.000000  7303.000000  \n",
       "mean      3.129851     0.991510     2.019033     1.502259     0.813501  \n",
       "std       1.791160     0.817291     1.410546     1.113137     0.389535  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.600000     0.000000     1.000000     1.000000     1.000000  \n",
       "50%       3.100000     1.000000     2.000000     1.000000     1.000000  \n",
       "75%       4.700000     2.000000     3.000000     2.000000     1.000000  \n",
       "max       6.200000     2.000000     4.000000     3.000000     1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id          0\n",
       "Age         0\n",
       "Sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has no missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Rename the columns in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data.rename(columns={'id': 'Id', 'age': 'Age', 'sex': 'Sex'}, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating the train and test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data[\"targ\"] = \"train\"\n",
    "test_data[\"targ\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16167</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11275</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13251</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19921</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11293</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>419</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7298</th>\n",
       "      <td>19401</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>10446</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>551</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300</th>\n",
       "      <td>13219</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>15349</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>15363</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7303 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  Age  Sex  cp  trestbps  chol  fbs  restecg  thalach  exang   \n",
       "0     16167   33    0   1       158   205    1        0      154      0  \\\n",
       "1     11275   53    1   2       198   154    0        1      104      0   \n",
       "2     13251   37    1   2       101   202    1        0      155      0   \n",
       "3     19921   75    0   0       113   306    1        2       88      1   \n",
       "4     11293   35    1   2       139   419    1        1      166      1   \n",
       "...     ...  ...  ...  ..       ...   ...  ...      ...      ...    ...   \n",
       "7298  19401   30    1   2       107   177    1        2      119      0   \n",
       "7299  10446   42    1   2        96   551    1        2       76      0   \n",
       "7300  13219   51    1   0       151   165    1        0      190      1   \n",
       "7301  15349   29    0   0       195   287    1        2      161      1   \n",
       "7302  15363   38    0   0       193   487    0        1      154      1   \n",
       "\n",
       "      oldpeak  slope  ca  thal  target   targ  \n",
       "0         1.5      1   4     1       1  train  \n",
       "1         0.8      2   1     0       0  train  \n",
       "2         2.1      1   3     1       1  train  \n",
       "3         4.9      0   2     2       1  train  \n",
       "4         0.9      2   4     0       1  train  \n",
       "...       ...    ...  ..   ...     ...    ...  \n",
       "7298      2.7      1   0     0       0  train  \n",
       "7299      1.9      2   3     2       1  train  \n",
       "7300      0.9      0   0     2       1  train  \n",
       "7301      3.4      1   1     0       1  train  \n",
       "7302      4.8      1   4     3       1  train  \n",
       "\n",
       "[7303 rows x 16 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_data, test_data], ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16167</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Age  Sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak   \n",
       "0  16167   33    0   1       158   205    1        0      154      0      1.5  \\\n",
       "\n",
       "   slope  ca  thal  target   targ  \n",
       "0      1   4     1     1.0  train  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16167</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11275</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13251</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19921</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11293</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>419</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Age  Sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak   \n",
       "0  16167   33    0   1       158   205    1        0      154      0      1.5  \\\n",
       "1  11275   53    1   2       198   154    0        1      104      0      0.8   \n",
       "2  13251   37    1   2       101   202    1        0      155      0      2.1   \n",
       "3  19921   75    0   0       113   306    1        2       88      1      4.9   \n",
       "4  11293   35    1   2       139   419    1        1      166      1      0.9   \n",
       "\n",
       "   slope  ca  thal  target   targ  \n",
       "0      1   4     1       1  train  \n",
       "1      2   1     0       0  train  \n",
       "2      1   3     1       1  train  \n",
       "3      0   2     2       1  train  \n",
       "4      2   4     0       1  train  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7303, 16), (2697, 15))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical features for easy data manipulation and EDA\n",
    "cat_cols = ['Sex', 'cp', 'fbs', 'exang', 'slope']\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id             0\n",
       "Age            0\n",
       "Sex            0\n",
       "cp             0\n",
       "trestbps       0\n",
       "chol           0\n",
       "fbs            0\n",
       "restecg        0\n",
       "thalach        0\n",
       "exang          0\n",
       "oldpeak        0\n",
       "slope          0\n",
       "ca             0\n",
       "thal           0\n",
       "target      2697\n",
       "targ           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking the distribution of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqbklEQVR4nO3df1SUdd7/8degzoA/ZkiTGVix6LZUijSxdO7KTWMlo856Z6XlprehHl1sF9jU5VRUbuWurZmVyqZr2Fk9pffetSV3IDf+2hR/RFFoaa3Zjbs2YBlMmoLCfP/ocH2doFISZujzfJwz5zjX9Zlr3pfnkM9mrhlsgUAgIAAAAINFhHoAAACAUCOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGC8zqEeoCNobGzU4cOH1aNHD9lstlCPAwAAzkIgENCXX36puLg4RUR892tABNFZOHz4sOLj40M9BgAAaIVDhw6pT58+37mGIDoLPXr0kPT1X6jT6QzxNAAA4Gz4/X7Fx8db/45/F4LoLDS9TeZ0OgkiAAA6mLO53IWLqgEAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGC3kQ/etf/9IvfvEL9erVS1FRUUpKStJbb71l7Q8EAsrNzVVsbKyioqKUkpKijz76KOgYR48e1cSJE+V0OhUdHa309HQdO3YsaM17772n66+/XpGRkYqPj9eCBQva5fwAAED4C2kQffHFF7r22mvVpUsXvfHGG3r//fe1cOFCXXDBBdaaBQsW6JlnnlFeXp527typbt26KTU1VSdPnrTWTJw4UXv37lVxcbHWr1+vrVu3avr06dZ+v9+v0aNH66KLLlJZWZmefPJJPfLII3r++efb9XwBAEB4sgUCgUConvy3v/2ttm3bpr///e8t7g8EAoqLi9NvfvMb3X///ZKk2tpaud1u5efna8KECfrggw+UmJio3bt3a+jQoZKkwsJC3XzzzfrnP/+puLg4LVu2TA888IB8Pp/sdrv13K+++qr27dvX7Hnr6upUV1dn3W/6XSi1tbX86g4AADoIv98vl8t1Vv9+h/QVotdee01Dhw7VHXfcoZiYGF111VVavny5tf/gwYPy+XxKSUmxtrlcLg0bNkylpaWSpNLSUkVHR1sxJEkpKSmKiIjQzp07rTUjRoywYkiSUlNTtX//fn3xxRfN5po/f75cLpd14zfdAwDw4xbSIPr444+1bNkyXXrppSoqKtLMmTP1q1/9SqtWrZIk+Xw+SZLb7Q56nNvttvb5fD7FxMQE7e/cubN69uwZtKalY5z5HGfKyclRbW2tdTt06NB5OFsAABCuQvrb7hsbGzV06FA98cQTkqSrrrpKe/bsUV5eniZPnhyyuRwOhxwOR8ieHwAAtK+QvkIUGxurxMTEoG0DBw5UZWWlJMnj8UiSqqqqgtZUVVVZ+zwej6qrq4P2nz59WkePHg1a09IxznwOAABgrpC+QnTttddq//79Qds+/PBDXXTRRZKkhIQEeTwelZSUaPDgwZK+vkBq586dmjlzpiTJ6/WqpqZGZWVlSk5OliRt3LhRjY2NGjZsmLXmgQce0KlTp9SlSxdJUnFxsfr37x/0iTYAaCuV85JCPQIQlvrmVoR6BEkhfoUoKytLO3bs0BNPPKF//OMfWrNmjZ5//nllZGRIkmw2mzIzM/XYY4/ptddeU0VFhSZNmqS4uDiNHTtW0tevKN10002aNm2adu3apW3btmnWrFmaMGGC4uLiJEl333237Ha70tPTtXfvXr388stavHixsrOzQ3XqAAAgjIT0FaKrr75ar7zyinJycjRv3jwlJCTo6aef1sSJE601c+bM0fHjxzV9+nTV1NTouuuuU2FhoSIjI601q1ev1qxZs3TjjTcqIiJC48aN0zPPPGPtd7lc2rBhgzIyMpScnKwLL7xQubm5Qd9VBAAAzBXS7yHqKM7lewwAoCW8ZQa0rC3fMusw30MEAAAQDggiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxgtpED3yyCOy2WxBtwEDBlj7T548qYyMDPXq1Uvdu3fXuHHjVFVVFXSMyspKpaWlqWvXroqJidHs2bN1+vTpoDWbN2/WkCFD5HA41K9fP+Xn57fH6QEAgA4i5K8QXX755fr000+t25tvvmnty8rK0uuvv65169Zpy5YtOnz4sG677TZrf0NDg9LS0lRfX6/t27dr1apVys/PV25urrXm4MGDSktL08iRI1VeXq7MzExNnTpVRUVF7XqeAAAgfHUO+QCdO8vj8TTbXltbqz//+c9as2aNRo0aJUl64YUXNHDgQO3YsUPDhw/Xhg0b9P777+t///d/5Xa7NXjwYP3ud7/T3Llz9cgjj8hutysvL08JCQlauHChJGngwIF68803tWjRIqWmprY4U11dnerq6qz7fr+/Dc4cAACEi5C/QvTRRx8pLi5Ol1xyiSZOnKjKykpJUllZmU6dOqWUlBRr7YABA9S3b1+VlpZKkkpLS5WUlCS3222tSU1Nld/v1969e601Zx6jaU3TMVoyf/58uVwu6xYfH3/ezhcAAISfkAbRsGHDlJ+fr8LCQi1btkwHDx7U9ddfry+//FI+n092u13R0dFBj3G73fL5fJIkn88XFENN+5v2fdcav9+vEydOtDhXTk6OamtrrduhQ4fOx+kCAIAwFdK3zMaMGWP9+corr9SwYcN00UUXae3atYqKigrZXA6HQw6HI2TPDwAA2lfI3zI7U3R0tC677DL94x//kMfjUX19vWpqaoLWVFVVWdcceTyeZp86a7r/fWucTmdIowsAAISPsAqiY8eO6cCBA4qNjVVycrK6dOmikpISa//+/ftVWVkpr9crSfJ6vaqoqFB1dbW1pri4WE6nU4mJidaaM4/RtKbpGAAAACENovvvv19btmzRJ598ou3bt+s//uM/1KlTJ911111yuVxKT09Xdna2Nm3apLKyMk2ZMkVer1fDhw+XJI0ePVqJiYm655579O6776qoqEgPPvigMjIyrLe8ZsyYoY8//lhz5szRvn37tHTpUq1du1ZZWVmhPHUAABBGQnoN0T//+U/ddddd+vzzz9W7d29dd9112rFjh3r37i1JWrRokSIiIjRu3DjV1dUpNTVVS5cutR7fqVMnrV+/XjNnzpTX61W3bt00efJkzZs3z1qTkJCggoICZWVlafHixerTp49WrFjxrR+5BwAA5rEFAoFAqIcId36/Xy6XS7W1tXI6naEeB0AHVDkvKdQjAGGpb25Fmx37XP79DqtriAAAAEKBIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGC8sAmi3//+97LZbMrMzLS2nTx5UhkZGerVq5e6d++ucePGqaqqKuhxlZWVSktLU9euXRUTE6PZs2fr9OnTQWs2b96sIUOGyOFwqF+/fsrPz2+HMwIAAB1FWATR7t279ac//UlXXnll0PasrCy9/vrrWrdunbZs2aLDhw/rtttus/Y3NDQoLS1N9fX12r59u1atWqX8/Hzl5uZaaw4ePKi0tDSNHDlS5eXlyszM1NSpU1VUVNRu5wcAAMJbyIPo2LFjmjhxopYvX64LLrjA2l5bW6s///nPeuqppzRq1CglJyfrhRde0Pbt27Vjxw5J0oYNG/T+++/rL3/5iwYPHqwxY8bod7/7nZYsWaL6+npJUl5enhISErRw4UINHDhQs2bN0u23365FixaF5HwBAED4CXkQZWRkKC0tTSkpKUHby8rKdOrUqaDtAwYMUN++fVVaWipJKi0tVVJSktxut7UmNTVVfr9fe/futdZ889ipqanWMVpSV1cnv98fdAMAAD9enUP55C+99JLefvtt7d69u9k+n88nu92u6OjooO1ut1s+n89ac2YMNe1v2vdda/x+v06cOKGoqKhmzz1//nw9+uijrT4vAADQsYTsFaJDhw7p17/+tVavXq3IyMhQjdGinJwc1dbWWrdDhw6FeiQAANCGQhZEZWVlqq6u1pAhQ9S5c2d17txZW7Zs0TPPPKPOnTvL7Xarvr5eNTU1QY+rqqqSx+ORJHk8nmafOmu6/31rnE5ni68OSZLD4ZDT6Qy6AQCAH6+QBdGNN96oiooKlZeXW7ehQ4dq4sSJ1p+7dOmikpIS6zH79+9XZWWlvF6vJMnr9aqiokLV1dXWmuLiYjmdTiUmJlprzjxG05qmYwAAAITsGqIePXroiiuuCNrWrVs39erVy9qenp6u7Oxs9ezZU06nU/fdd5+8Xq+GDx8uSRo9erQSExN1zz33aMGCBfL5fHrwwQeVkZEhh8MhSZoxY4aee+45zZkzR/fee682btyotWvXqqCgoH1PGAAAhK2QXlT9fRYtWqSIiAiNGzdOdXV1Sk1N1dKlS639nTp10vr16zVz5kx5vV5169ZNkydP1rx586w1CQkJKigoUFZWlhYvXqw+ffpoxYoVSk1NDcUpAQCAMGQLBAKBUA8R7vx+v1wul2pra7meCECrVM5LCvUIQFjqm1vRZsc+l3+/Q/49RAAAAKFGEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMF6rgmjUqFGqqalptt3v92vUqFE/dCYAAIB21aog2rx5s+rr65ttP3nypP7+97//4KEAAADaU+dzWfzee+9Zf37//ffl8/ms+w0NDSosLNRPfvKT8zcdAABAOzinIBo8eLBsNptsNluLb41FRUXp2WefPW/DAQAAtIdzCqKDBw8qEAjokksu0a5du9S7d29rn91uV0xMjDp16nTehwQAAGhL5xREF110kSSpsbGxTYYBAAAIhXMKojN99NFH2rRpk6qrq5sFUm5u7g8eDAAAoL20KoiWL1+umTNn6sILL5TH45HNZrP22Ww2gggAAHQorQqixx57TI8//rjmzp17vucBAABod636HqIvvvhCd9xxx/meBQAAICRaFUR33HGHNmzYcL5nAQAACIlWvWXWr18/PfTQQ9qxY4eSkpLUpUuXoP2/+tWvzstwAAAA7cEWCAQC5/qghISEbz+gzaaPP/74Bw0Vbvx+v1wul2pra+V0OkM9DoAOqHJeUqhHAMJS39yKNjv2ufz73apXiA4ePNiqwQAAAMJRq64hAgAA+DFp1StE995773fuX7lyZauGAQAACIVWBdEXX3wRdP/UqVPas2ePampqWvylrwAAAOGsVUH0yiuvNNvW2NiomTNn6t/+7d9+8FAAAADt6bxdQxQREaHs7GwtWrTofB0SAACgXZzXi6oPHDig06dPn89DAgAAtLlWBVF2dnbQLSsrSxMmTND48eM1fvz4sz7OsmXLdOWVV8rpdMrpdMrr9eqNN96w9p88eVIZGRnq1auXunfvrnHjxqmqqiroGJWVlUpLS1PXrl0VExOj2bNnN4uyzZs3a8iQIXI4HOrXr5/y8/Nbc9oAAOBHqlXXEL3zzjtB9yMiItS7d28tXLjwez+BdqY+ffro97//vS699FIFAgGtWrVKP//5z/XOO+/o8ssvV1ZWlgoKCrRu3Tq5XC7NmjVLt912m7Zt2yZJamhoUFpamjwej7Zv365PP/1UkyZNUpcuXfTEE09I+vo7k9LS0jRjxgytXr1aJSUlmjp1qmJjY5Wamtqa0wcAAD8yrfqm6rbUs2dPPfnkk7r99tvVu3dvrVmzRrfffrskad++fRo4cKBKS0s1fPhwvfHGG7rlllt0+PBhud1uSVJeXp7mzp2rI0eOyG63a+7cuSooKNCePXus55gwYYJqampUWFh4VjPxTdUAfii+qRpoWbh8U/UPuoboyJEjevPNN/Xmm2/qyJEjP+RQamho0EsvvaTjx4/L6/WqrKxMp06dUkpKirVmwIAB6tu3r0pLSyVJpaWlSkpKsmJIklJTU+X3+7V3715rzZnHaFrTdIyW1NXVye/3B90AAMCPV6uC6Pjx47r33nsVGxurESNGaMSIEYqLi1N6erq++uqrczpWRUWFunfvLofDoRkzZuiVV15RYmKifD6f7Ha7oqOjg9a73W75fD5Jks/nC4qhpv1N+75rjd/v14kTJ1qcaf78+XK5XNYtPj7+nM4JAAB0LK2+qHrLli16/fXXVVNTo5qaGv3tb3/Tli1b9Jvf/OacjtW/f3+Vl5dr586dmjlzpiZPnqz333+/NWOdNzk5OaqtrbVuhw4dCuk8AACgbbXqouq//vWv+q//+i/dcMMN1rabb75ZUVFRuvPOO7Vs2bKzPpbdble/fv0kScnJydq9e7cWL16s8ePHq76+XjU1NUGvElVVVcnj8UiSPB6Pdu3aFXS8pk+hnbnmm59Mq6qqktPpVFRUVIszORwOORyOsz4HAADQsbXqFaKvvvqq2dtQkhQTE3POb5l9U2Njo+rq6pScnKwuXbqopKTE2rd//35VVlbK6/VKkrxeryoqKlRdXW2tKS4ultPpVGJiorXmzGM0rWk6BgAAQKuCyOv16uGHH9bJkyetbSdOnNCjjz56TqGRk5OjrVu36pNPPlFFRYVycnK0efNmTZw4US6XS+np6crOztamTZtUVlamKVOmyOv1avjw4ZKk0aNHKzExUffcc4/effddFRUV6cEHH1RGRob1Cs+MGTP08ccfa86cOdq3b5+WLl2qtWvXKisrqzWnDgAAfoRa9ZbZ008/rZtuukl9+vTRoEGDJEnvvvuuHA6HNmzYcNbHqa6u1qRJk/Tpp5/K5XLpyiuvVFFRkX72s59JkhYtWqSIiAiNGzdOdXV1Sk1N1dKlS63Hd+rUSevXr9fMmTPl9XrVrVs3TZ48WfPmzbPWJCQkqKCgQFlZWVq8eLH69OmjFStW8B1EAADA0urvIfrqq6+0evVq7du3T5I0cOBATZw48Vuvy+nI+B4iAD8U30MEtCxcvoeoVa8QzZ8/X263W9OmTQvavnLlSh05ckRz585tzWEBAABColXXEP3pT3/SgAEDmm2//PLLlZeX94OHAgAAaE+tCiKfz6fY2Nhm23v37q1PP/30Bw8FAADQnloVRPHx8dYvWD3Ttm3bFBcX94OHAgAAaE+tuoZo2rRpyszM1KlTpzRq1ChJUklJiebMmXPO31QNAAAQaq0KotmzZ+vzzz/XL3/5S9XX10uSIiMjNXfuXOXk5JzXAQEAANpaq4LIZrPpD3/4gx566CF98MEHioqK0qWXXsqvuwAAAB1Sq4KoSffu3XX11Vefr1kAAABColUXVQMAAPyYEEQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOOFNIjmz5+vq6++Wj169FBMTIzGjh2r/fv3B605efKkMjIy1KtXL3Xv3l3jxo1TVVVV0JrKykqlpaWpa9euiomJ0ezZs3X69OmgNZs3b9aQIUPkcDjUr18/5efnt/XpAQCADiKkQbRlyxZlZGRox44dKi4u1qlTpzR69GgdP37cWpOVlaXXX39d69at05YtW3T48GHddttt1v6GhgalpaWpvr5e27dv16pVq5Sfn6/c3FxrzcGDB5WWlqaRI0eqvLxcmZmZmjp1qoqKitr1fAEAQHiyBQKBQKiHaHLkyBHFxMRoy5YtGjFihGpra9W7d2+tWbNGt99+uyRp3759GjhwoEpLSzV8+HC98cYbuuWWW3T48GG53W5JUl5enubOnasjR47Ibrdr7ty5Kigo0J49e6znmjBhgmpqalRYWNhsjrq6OtXV1Vn3/X6/4uPjVVtbK6fT2cZ/CwB+jCrnJYV6BCAs9c2taLNj+/1+uVyus/r3O6yuIaqtrZUk9ezZU5JUVlamU6dOKSUlxVozYMAA9e3bV6WlpZKk0tJSJSUlWTEkSampqfL7/dq7d6+15sxjNK1pOsY3zZ8/Xy6Xy7rFx8efv5MEAABhJ2yCqLGxUZmZmbr22mt1xRVXSJJ8Pp/sdruio6OD1rrdbvl8PmvNmTHUtL9p33et8fv9OnHiRLNZcnJyVFtba90OHTp0Xs4RAACEp86hHqBJRkaG9uzZozfffDPUo8jhcMjhcIR6DAAA0E7C4hWiWbNmaf369dq0aZP69Oljbfd4PKqvr1dNTU3Q+qqqKnk8HmvNNz911nT/+9Y4nU5FRUWd79MBAAAdTEiDKBAIaNasWXrllVe0ceNGJSQkBO1PTk5Wly5dVFJSYm3bv3+/Kisr5fV6JUler1cVFRWqrq621hQXF8vpdCoxMdFac+YxmtY0HQMAAJgtpG+ZZWRkaM2aNfrb3/6mHj16WNf8uFwuRUVFyeVyKT09XdnZ2erZs6ecTqfuu+8+eb1eDR8+XJI0evRoJSYm6p577tGCBQvk8/n04IMPKiMjw3rba8aMGXruuec0Z84c3Xvvvdq4caPWrl2rgoKCkJ07AAAIHyF9hWjZsmWqra3VDTfcoNjYWOv28ssvW2sWLVqkW265RePGjdOIESPk8Xj03//939b+Tp06af369erUqZO8Xq9+8YtfaNKkSZo3b561JiEhQQUFBSouLtagQYO0cOFCrVixQqmpqe16vgAAIDyF1fcQhatz+R4DAGgJ30MEtIzvIQIAAAgTBBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMF7nUA+A/y959ouhHgEIS2VPTgr1CAB+5HiFCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYL6RBtHXrVt16662Ki4uTzWbTq6++GrQ/EAgoNzdXsbGxioqKUkpKij766KOgNUePHtXEiRPldDoVHR2t9PR0HTt2LGjNe++9p+uvv16RkZGKj4/XggUL2vrUAABABxLSIDp+/LgGDRqkJUuWtLh/wYIFeuaZZ5SXl6edO3eqW7duSk1N1cmTJ601EydO1N69e1VcXKz169dr69atmj59urXf7/dr9OjRuuiii1RWVqYnn3xSjzzyiJ5//vk2Pz8AANAxdA7lk48ZM0ZjxoxpcV8gENDTTz+tBx98UD//+c8lSS+++KLcbrdeffVVTZgwQR988IEKCwu1e/duDR06VJL07LPP6uabb9Yf//hHxcXFafXq1aqvr9fKlStlt9t1+eWXq7y8XE899VRQOJ2prq5OdXV11n2/33+ezxwAAISTsL2G6ODBg/L5fEpJSbG2uVwuDRs2TKWlpZKk0tJSRUdHWzEkSSkpKYqIiNDOnTutNSNGjJDdbrfWpKamav/+/friiy9afO758+fL5XJZt/j4+LY4RQAAECbCNoh8Pp8kye12B213u93WPp/Pp5iYmKD9nTt3Vs+ePYPWtHSMM5/jm3JyclRbW2vdDh069MNPCAAAhK2QvmUWrhwOhxwOR6jHAAAA7SRsXyHyeDySpKqqqqDtVVVV1j6Px6Pq6uqg/adPn9bRo0eD1rR0jDOfAwAAmC1sgyghIUEej0clJSXWNr/fr507d8rr9UqSvF6vampqVFZWZq3ZuHGjGhsbNWzYMGvN1q1bderUKWtNcXGx+vfvrwsuuKCdzgYAAISzkAbRsWPHVF5ervLycklfX0hdXl6uyspK2Ww2ZWZm6rHHHtNrr72miooKTZo0SXFxcRo7dqwkaeDAgbrppps0bdo07dq1S9u2bdOsWbM0YcIExcXFSZLuvvtu2e12paena+/evXr55Ze1ePFiZWdnh+isAQBAuAnpNURvvfWWRo4cad1vipTJkycrPz9fc+bM0fHjxzV9+nTV1NTouuuuU2FhoSIjI63HrF69WrNmzdKNN96oiIgIjRs3Ts8884y13+VyacOGDcrIyFBycrIuvPBC5ebmfutH7gEAgHlsgUAgEOohwp3f75fL5VJtba2cTmebPU/y7Bfb7NhAR1b25KRQj/CDVc5LCvUIQFjqm1vRZsc+l3+/w/YaIgAAgPZCEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADCeUUG0ZMkSXXzxxYqMjNSwYcO0a9euUI8EAADCgDFB9PLLLys7O1sPP/yw3n77bQ0aNEipqamqrq4O9WgAACDEjAmip556StOmTdOUKVOUmJiovLw8de3aVStXrgz1aAAAIMQ6h3qA9lBfX6+ysjLl5ORY2yIiIpSSkqLS0tJm6+vq6lRXV2fdr62tlST5/f42nbOh7kSbHh/oqNr6Z689fHmyIdQjAGGpLX++m44dCAS+d60RQfTZZ5+poaFBbrc7aLvb7da+ffuarZ8/f74effTRZtvj4+PbbEYA38717IxQjwCgrcx3tflTfPnll3K5vvt5jAiic5WTk6Ps7GzrfmNjo44ePapevXrJZrOFcDK0B7/fr/j4eB06dEhOpzPU4wA4j/j5NksgENCXX36puLi4711rRBBdeOGF6tSpk6qqqoK2V1VVyePxNFvvcDjkcDiCtkVHR7fliAhDTqeT/2ACP1L8fJvj+14ZamLERdV2u13JyckqKSmxtjU2NqqkpERerzeEkwEAgHBgxCtEkpSdna3Jkydr6NChuuaaa/T000/r+PHjmjJlSqhHAwAAIWZMEI0fP15HjhxRbm6ufD6fBg8erMLCwmYXWgMOh0MPP/xws7dNAXR8/Hzj29gCZ/NZNAAAgB8xI64hAgAA+C4EEQAAMB5BBAAAjEcQAQAA4xFEMNKSJUt08cUXKzIyUsOGDdOuXbu+c/26des0YMAARUZGKikpSf/zP//TTpMCOBdbt27Vrbfeqri4ONlsNr366qvf+5jNmzdryJAhcjgc6tevn/Lz89t8ToQfggjGefnll5Wdna2HH35Yb7/9tgYNGqTU1FRVV1e3uH779u266667lJ6ernfeeUdjx47V2LFjtWfPnnaeHMD3OX78uAYNGqQlS5ac1fqDBw8qLS1NI0eOVHl5uTIzMzV16lQVFRW18aQIN3zsHsYZNmyYrr76aj333HOSvv7W8vj4eN1333367W9/22z9+PHjdfz4ca1fv97aNnz4cA0ePFh5eXntNjeAc2Oz2fTKK69o7Nix37pm7ty5KigoCPofnAkTJqimpkaFhYXtMCXCBa8QwSj19fUqKytTSkqKtS0iIkIpKSkqLS1t8TGlpaVB6yUpNTX1W9cD6Dj4+UYTgghG+eyzz9TQ0NDsG8rdbrd8Pl+Lj/H5fOe0HkDH8W0/336/XydOnAjRVAgFgggAABiPIIJRLrzwQnXq1ElVVVVB26uqquTxeFp8jMfjOaf1ADqOb/v5djqdioqKCtFUCAWCCEax2+1KTk5WSUmJta2xsVElJSXyer0tPsbr9Qatl6Ti4uJvXQ+g4+DnG00IIhgnOztby5cv16pVq/TBBx9o5syZOn78uKZMmSJJmjRpknJycqz1v/71r1VYWKiFCxdq3759euSRR/TWW29p1qxZoToFAN/i2LFjKi8vV3l5uaSvP1ZfXl6uyspKSVJOTo4mTZpkrZ8xY4Y+/vhjzZkzR/v27dPSpUu1du1aZWVlhWJ8hFIAMNCzzz4b6Nu3b8ButweuueaawI4dO6x9P/3pTwOTJ08OWr927drAZZddFrDb7YHLL788UFBQ0M4TAzgbmzZtCkhqdmv6mZ48eXLgpz/9abPHDB48OGC32wOXXHJJ4IUXXmj3uRF6fA8RAAAwHm+ZAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAA6pBtuuEGZmZmhHsMSbvMAODcEEQBj1dfXh3oEAGGCIALQ4fznf/6ntmzZosWLF8tms8lms+nAgQNKT09XQkKCoqKi1L9/fy1evLjZ48aOHavHH39ccXFx6t+/vyRp+/btGjx4sCIjIzV06FC9+uqrstls1m9Ml6Q9e/ZozJgx6t69u9xut+655x599tln3zrPJ5980l5/HQDOg86hHgAAztXixYv14Ycf6oorrtC8efMkSRdccIH69OmjdevWqVevXtq+fbumT5+u2NhY3XnnndZjS0pK5HQ6VVxcLEny+/269dZbdfPNN2vNmjX6v//7v2ZvfdXU1GjUqFGaOnWqFi1apBMnTmju3Lm68847tXHjxhbn6d27d/v8ZQA4LwgiAB2Oy+WS3W5X165d5fF4rO2PPvqo9eeEhASVlpZq7dq1QUHUrVs3rVixQna7XZKUl5cnm82m5cuXKzIyUomJifrXv/6ladOmWY957rnndNVVV+mJJ56wtq1cuVLx8fH68MMPddlll7U4D4COgyAC8KOxZMkSrVy5UpWVlTpx4oTq6+s1ePDgoDVJSUlWDEnS/v37deWVVyoyMtLads011wQ95t1339WmTZvUvXv3Zs954MABXXbZZef3RAC0O4IIwI/CSy+9pPvvv18LFy6U1+tVjx499OSTT2rnzp1B67p163bOxz527JhuvfVW/eEPf2i2LzY2ttUzAwgfBBGADslut6uhocG6v23bNv37v/+7fvnLX1rbDhw48L3H6d+/v/7yl7+orq5ODodDkrR79+6gNUOGDNFf//pXXXzxxercueX/bH5zHgAdC58yA9AhXXzxxdq5c6c++eQTffbZZ7r00kv11ltvqaioSB9++KEeeuihZmHTkrvvvluNjY2aPn26PvjgAxUVFemPf/yjJMlms0mSMjIydPToUd11113avXu3Dhw4oKKiIk2ZMsWKoG/O09jY2HYnD+C8I4gAdEj333+/OnXqpMTERPXu3Vupqam67bbbNH78eA0bNkyff/550KtF38bpdOr1119XeXm5Bg8erAceeEC5ubmSZF1XFBcXp23btqmhoUGjR49WUlKSMjMzFR0drYiIiBbnqaysbLuTB3De2QKBQCDUQwBAOFm9erWmTJmi2tpaRUVFhXocAO2Aa4gAGO/FF1/UJZdcop/85Cd69913re8YIoYAcxBEAIzn8/mUm5srn8+n2NhY3XHHHXr88cdDPRaAdsRbZgAAwHhcVA0AAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAw3v8D7jstRoeMQGAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=df['target']);  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to group the ages into bins\n",
    "def group_age(x):\n",
    "    if x < 30:\n",
    "        return 'Young'\n",
    "    elif 30 <= x < 40:\n",
    "        return 'Adult'\n",
    "    elif 40 <= x < 60:\n",
    "        return 'Middle Age'\n",
    "    else:\n",
    "        return 'Old'\n",
    "\n",
    "df['Age_bin'] = df['Age'].apply(group_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 17 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Id        10000 non-null  int64  \n",
      " 1   Age       10000 non-null  int64  \n",
      " 2   Sex       10000 non-null  object \n",
      " 3   cp        10000 non-null  object \n",
      " 4   trestbps  10000 non-null  int64  \n",
      " 5   chol      10000 non-null  int64  \n",
      " 6   fbs       10000 non-null  object \n",
      " 7   restecg   10000 non-null  int64  \n",
      " 8   thalach   10000 non-null  int64  \n",
      " 9   exang     10000 non-null  object \n",
      " 10  oldpeak   10000 non-null  float64\n",
      " 11  slope     10000 non-null  object \n",
      " 12  ca        10000 non-null  int64  \n",
      " 13  thal      10000 non-null  int64  \n",
      " 14  target    7303 non-null   float64\n",
      " 15  targ      10000 non-null  object \n",
      " 16  Age_bin   10000 non-null  object \n",
      "dtypes: float64(2), int64(8), object(7)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding the categorical columns\n",
    "cat_cols.append('Age_bin')\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>targ</th>\n",
       "      <th>Age_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16167</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11275</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13251</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19921</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11293</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>419</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Age  Sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak   \n",
       "0  16167   33    0   1       158   205    1        0      154      0      1.5  \\\n",
       "1  11275   53    1   2       198   154    0        1      104      0      0.8   \n",
       "2  13251   37    1   2       101   202    1        0      155      0      2.1   \n",
       "3  19921   75    0   0       113   306    1        2       88      1      4.9   \n",
       "4  11293   35    1   2       139   419    1        1      166      1      0.9   \n",
       "\n",
       "   slope  ca  thal  target   targ  Age_bin  \n",
       "0      1   4     1     1.0  train        0  \n",
       "1      2   1     0     0.0  train        1  \n",
       "2      1   3     1     1.0  train        0  \n",
       "3      0   2     2     1.0  train        2  \n",
       "4      2   4     0     1.0  train        0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16167</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11275</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Age  Sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak   \n",
       "0  16167   33    0   1       158   205    1        0      154      0      1.5  \\\n",
       "1  11275   53    1   2       198   154    0        1      104      0      0.8   \n",
       "\n",
       "   slope  ca  thal  target   targ  \n",
       "0      1   4     1       1  train  \n",
       "1      2   1     0       0  train  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[df[\"targ\"] == \"train\"].drop([\"targ\", \"Age\", \"Id\"], axis=1)\n",
    "test_data = df[df[\"targ\"] == \"test\"].drop([\"targ\", \"target\", \"Age\", \"Id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# List of continuous features\n",
    "continuous_features = [ 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "# Create boxplots to visualize outliers\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, feature in enumerate(continuous_features, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.boxplot(data=train_data, y=feature)\n",
    "    plt.title(f'Boxplot of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7303, 14)\n"
     ]
    }
   ],
   "source": [
    "# Define the function to handle outliers using IQR\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # Filter out rows with outliers\n",
    "    df_filtered = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df_filtered\n",
    "\n",
    "# Apply IQR method for each continuous feature\n",
    "for feature in continuous_features:\n",
    "    train_data = remove_outliers_iqr(train_data, feature)\n",
    "\n",
    "# Check the number of rows after removing outliers\n",
    "print(train_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>Age_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>419</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  ca   \n",
       "0    0   1       158   205    1        0      154      0      1.5      1   4  \\\n",
       "1    1   2       198   154    0        1      104      0      0.8      2   1   \n",
       "2    1   2       101   202    1        0      155      0      2.1      1   3   \n",
       "3    0   0       113   306    1        2       88      1      4.9      0   2   \n",
       "4    1   2       139   419    1        1      166      1      0.9      2   4   \n",
       "\n",
       "   thal  Age_bin  \n",
       "0     1        0  \n",
       "1     0        1  \n",
       "2     1        0  \n",
       "3     2        2  \n",
       "4     0        0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data.drop(columns=[\"target\"])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "1.0    5941\n",
      "0.0    1362\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = train_data[\"target\"]\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "Age_bin     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id             0\n",
       "Age            0\n",
       "Sex            0\n",
       "cp             0\n",
       "trestbps       0\n",
       "chol           0\n",
       "fbs            0\n",
       "restecg        0\n",
       "thalach        0\n",
       "exang          0\n",
       "oldpeak        0\n",
       "slope          0\n",
       "ca             0\n",
       "thal           0\n",
       "target      2697\n",
       "targ           0\n",
       "Age_bin        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "Age_bin     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5842, 13), (1461, 13))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5842,), (1461,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      "target\n",
      "1.0    5941\n",
      "0.0    1362\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution after SMOTE:\n",
      "target\n",
      "1.0    4740\n",
      "0.0    4740\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# resampling the data using SMOTE because the target variable is imbalanced\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    " #Print class distribution before and after SMOTE\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      "target\n",
      "1.0    5941\n",
      "0.0    1362\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution after SMOTE:\n",
      "target\n",
      "1.0    4740\n",
      "0.0    4740\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    " #Print class distribution before and after SMOTE\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.39      0.03      0.06       260\n",
      "         1.0       0.83      0.99      0.90      1201\n",
      "\n",
      "    accuracy                           0.82      1461\n",
      "   macro avg       0.61      0.51      0.48      1461\n",
      "weighted avg       0.75      0.82      0.75      1461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9872362869198312\n",
      "Test Accuracy: 0.8186173853524983\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on train and test data\n",
    "acc_train = model.score(X_resampled, y_resampled)\n",
    "acc_test = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Training Accuracy:\", acc_train)\n",
    "print(\"Test Accuracy:\", acc_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id\n",
       "0  16501\n",
       "1  10444\n",
       "2  14288\n",
       "3  10409\n",
       "4  17330"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'ID': sub['Id'], \n",
    "    'Target': test_pred\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission.to_csv('XGBClassifier001.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using standard scaler, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.37      1.00      0.54       260\n",
      "         1.0       1.00      0.63      0.77      1201\n",
      "\n",
      "    accuracy                           0.69      1461\n",
      "   macro avg       0.68      0.81      0.66      1461\n",
      "weighted avg       0.89      0.69      0.73      1461\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model1 = LogisticRegression()\n",
    "\n",
    "\n",
    "model1.fit(X_resampled, y_resampled)\n",
    "\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "\n",
    "y_pred = model1.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9872362869198312\n",
      "Test Accuracy: 0.8186173853524983\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on train and test data\n",
    "acc_train = model.score(X_resampled, y_resampled)\n",
    "acc_test = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Training Accuracy:\", acc_train)\n",
    "print(\"Test Accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_pred = model1.predict(test_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16501</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10444</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14288</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10409</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17330</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id   id\n",
       "0  16501  1.0\n",
       "1  10444  1.0\n",
       "2  14288  1.0\n",
       "3  10409  1.0\n",
       "4  17330  0.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['id'] = test_pred\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('LogisticRegression001.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 accuracy: 0.8237547892720306\n",
      "Fold 2 accuracy: 0.8122605363984674\n",
      "Fold 3 accuracy: 0.8360498561840843\n",
      "Fold 4 accuracy: 0.8312559923298178\n",
      "Fold 5 accuracy: 0.8245445829338447\n",
      "Fold 6 accuracy: 0.8101629913710451\n",
      "Fold 7 accuracy: 0.8331735378715245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize lists to store out-of-fold predictions and scores\n",
    "fold_pred = []   \n",
    "oof_pred = []\n",
    "\n",
    "# Set hyperparameters for the classifier\n",
    "params = {\n",
    "    'learning_rate': 0.163251453473545997,\n",
    "    'max_depth': 14,\n",
    "    'subsample': 0.6530887571489526,\n",
    "    'loss_function': 'Logloss',  \n",
    "    'eval_metric': 'Accuracy'  # Metric for evaluating model performance during training\n",
    "}\n",
    "\n",
    "# Create a KFold with 7 splits and set the random state\n",
    "fold = KFold(n_splits=7, shuffle=True, random_state=150)\n",
    "\n",
    "# Start the KFold process\n",
    "for i, (train_index, test_index) in enumerate(fold.split(X, y), start=1):\n",
    "    X_resampled, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_resampled, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Initialize and train the CatBoost Classifier\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        X_resampled, y_resampled,\n",
    "        eval_set=[(X_resampled, y_resampled), (X_test, y_test)],\n",
    "        early_stopping_rounds=200, \n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Make probability predictions on the test set\n",
    "    preds_proba = model.predict_proba(X_test)[:, 1]  # Get probabilities for class 1\n",
    "    preds = (preds_proba >= 0.5).astype(int)  # Convert probabilities to 0 or 1 based on threshold 0.5\n",
    "\n",
    "    # Calculate and print the accuracy error for the fold\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    print(f\"Fold {i} accuracy: {accuracy}\")\n",
    "    oof_pred.append(accuracy)\n",
    "\n",
    "    # Predict on test_data using probabilities and convert to 0 or 1\n",
    "    test_proba = model.predict_proba(test_data)[:, 1]\n",
    "    test_preds = (test_proba >= 0.5).astype(int)\n",
    "    fold_pred.append(test_preds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fold_pred to a 2D array for aggregation\n",
    "fold_pred_array = np.array(fold_pred)  # Shape: (n_folds, n_samples)\n",
    "\n",
    "# Combine predictions using mean across folds\n",
    "final_preds_proba = fold_pred_array.mean(axis=0)  # Mean probability across folds\n",
    "final_preds = (final_preds_proba >= 0.5).astype(int)  # Convert to binary predictions\n",
    "\n",
    "\n",
    "sub['id'] = final_preds \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  id\n",
       "0  16501   1\n",
       "1  10444   1\n",
       "2  14288   1\n",
       "3  10409   1\n",
       "4  17330   1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "sub.to_csv('Catboost_kfold_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.7199 - loss: 0.5665 - val_accuracy: 0.8163 - val_loss: 0.3784\n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8176 - loss: 0.3509 - val_accuracy: 0.8067 - val_loss: 0.3183\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.3088 - val_accuracy: 0.8131 - val_loss: 0.3000\n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.3003 - val_accuracy: 0.8275 - val_loss: 0.2867\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8123 - loss: 0.2845 - val_accuracy: 0.8131 - val_loss: 0.2820\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8143 - loss: 0.2781 - val_accuracy: 0.7971 - val_loss: 0.2774\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8256 - loss: 0.2658 - val_accuracy: 0.8035 - val_loss: 0.2763\n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8246 - loss: 0.2638 - val_accuracy: 0.8035 - val_loss: 0.2758\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8173 - loss: 0.2729 - val_accuracy: 0.7955 - val_loss: 0.2731\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.2600 - val_accuracy: 0.8067 - val_loss: 0.2738\n",
      "Epoch 11/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.2647 - val_accuracy: 0.8067 - val_loss: 0.2733\n",
      "Epoch 12/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.2579 - val_accuracy: 0.8067 - val_loss: 0.2731\n",
      "Epoch 13/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.2565 - val_accuracy: 0.8099 - val_loss: 0.2702\n",
      "Epoch 14/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8439 - loss: 0.2507 - val_accuracy: 0.8019 - val_loss: 0.2715\n",
      "Epoch 15/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.2542 - val_accuracy: 0.8019 - val_loss: 0.2734\n",
      "Epoch 16/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.2619 - val_accuracy: 0.8147 - val_loss: 0.2736\n",
      "\u001b[1m33/33\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Accuracy: 0.8322\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.50      0.51       179\n",
      "         1.0       0.90      0.90      0.90       864\n",
      "\n",
      "    accuracy                           0.83      1043\n",
      "   macro avg       0.70      0.70      0.70      1043\n",
      "weighted avg       0.83      0.83      0.83      1043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the ANN\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=X_resampled_scaled.shape[1]))  # Input layer\n",
    "model.add(Dense(16, activation='relu'))  # Hidden layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_resampled_scaled, y_resampled, \n",
    "                    validation_split=0.1, \n",
    "                    epochs=100, \n",
    "                    batch_size=32, \n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "test_predictions_classes = (test_predictions > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Calculate accuracy and print classification report\n",
    "accuracy = accuracy_score(y_test, test_predictions_classes)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, test_predictions_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the actual test dataset\n",
    "final_test_predictions = model.predict(scaler.transform(test_data))\n",
    "final_test_predictions_classes = (final_test_predictions > 0.5).astype(int)\n",
    "\n",
    "# Create a submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'ID': sub['Id'], \n",
    "    'Target': final_test_predictions_classes.flatten()  \n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission.to_csv('submission_ann003.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 18.4 s\n",
      "Wall time: 19.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lg_params = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'solver':['saga'],\n",
    "    'class_weight':['balanced']}\n",
    "\n",
    "lg_gs = GridSearchCV(LogisticRegression(random_state=12345),\n",
    "                 lg_params,\n",
    "                 cv = 5,\n",
    "                 scoring = 'roc_auc')\n",
    "lg = lg_gs.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.22 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt_params = {\n",
    "    'max_depth': [2, 4, 8, 16],\n",
    "    'min_samples_split': range(5,55,10), \n",
    "    'min_samples_leaf': [2, 3, 5, 10],\n",
    "    'class_weight':['balanced']\n",
    "}\n",
    "\n",
    "dt_gs_auc = GridSearchCV(DecisionTreeClassifier(random_state=12345),\n",
    "                         dt_params, n_jobs=-1, cv = 5, scoring = 'roc_auc')\n",
    "dt_auc = dt_gs_auc.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=30; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=3, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=2, min_samples_leaf=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=3, n_estimators=50; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=30; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=4, min_samples_leaf=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=30; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=30; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=30; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=30; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=10; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=10; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=30; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=30; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=30; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=30; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=30; total time=   0.8s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=2; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=5; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=10; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=10; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=10; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=10; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=30; total time=   1.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=30; total time=   1.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=30; total time=   1.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=30; total time=   1.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=30; total time=   1.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=50; total time=   1.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=50; total time=   1.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=50; total time=   1.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=50; total time=   2.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=3, n_estimators=50; total time=   1.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=10; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=10; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=30; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=30; total time=   1.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=30; total time=   1.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=30; total time=   1.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=30; total time=   1.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=50; total time=   2.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=50; total time=   1.7s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=30; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=30; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=30; total time=   1.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=30; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=30; total time=   0.8s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=50; total time=   1.6s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_leaf=10, n_estimators=50; total time=   1.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=3, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=30; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=30; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=30; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=30; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=30; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=30; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=2, min_samples_leaf=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=30; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=30; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=3, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=30; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=4, min_samples_leaf=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=30; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=30; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=10; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=10; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=10; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=30; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=30; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=30; total time=   1.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=30; total time=   0.8s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=50; total time=   1.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=10; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=30; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=30; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=30; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=30; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=30; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=30; total time=   0.9s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=8, min_samples_leaf=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=10; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=10; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=10; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=10; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=30; total time=   1.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=30; total time=   0.9s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=30; total time=   1.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=30; total time=   0.9s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=30; total time=   0.9s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=50; total time=   1.8s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=50; total time=   2.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=50; total time=   1.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=2; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=2; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=5; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=10; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=10; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=10; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=10; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=10; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=30; total time=   0.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=30; total time=   0.9s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=30; total time=   1.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=30; total time=   1.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=30; total time=   1.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=50; total time=   2.7s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=50; total time=   2.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=50; total time=   1.7s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=50; total time=   1.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=3, n_estimators=50; total time=   1.9s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=10; total time=   0.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=10; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=30; total time=   0.9s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=30; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=30; total time=   1.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=30; total time=   1.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=30; total time=   1.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=50; total time=   1.6s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=50; total time=   1.8s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=5, n_estimators=50; total time=   2.4s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=2; total time=   0.0s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=5; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=10; total time=   0.5s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=10; total time=   0.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=10; total time=   0.2s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=10; total time=   0.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=30; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=30; total time=   0.8s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=30; total time=   0.7s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=30; total time=   1.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=30; total time=   1.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=50; total time=   1.3s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=50; total time=   1.8s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=50; total time=   1.8s\n",
      "[CV] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_leaf=10, n_estimators=50; total time=   1.4s\n",
      "CPU times: total: 4min 45s\n",
      "Wall time: 4min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_params = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'n_estimators': [2, 5, 10, 30, 50],\n",
    "    'max_depth': [2, 4, 8, 16],\n",
    "    'min_samples_leaf': [2,3,5,10],\n",
    "    'class_weight':['balanced']\n",
    "}\n",
    "\n",
    "rf_gs = GridSearchCV(RandomForestClassifier(random_state=12345),\n",
    "                     rf_params, cv = 5, scoring = 'roc_auc',\n",
    "                     verbose=2)\n",
    "rf_auc = rf_gs.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=16,\n",
       "                       min_samples_leaf=10, n_estimators=50,\n",
       "                       random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=16,\n",
       "                       min_samples_leaf=10, n_estimators=50,\n",
       "                       random_state=12345)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=16,\n",
       "                       min_samples_leaf=10, n_estimators=50,\n",
       "                       random_state=12345)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = RandomForestClassifier(random_state=12345, max_depth=16, n_estimators=50, min_samples_leaf=10, criterion='gini', class_weight='balanced')\n",
    "cls.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=12345)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(random_state=12345)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grb = GradientBoostingClassifier(random_state=12345)\n",
    "grb.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = cls.predict(test_data)\n",
    "\n",
    " \n",
    "sub['id'] = predictions\n",
    "sub.to_csv('cls007.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = lg.predict(test_data)\n",
    "\n",
    " \n",
    "sub['id'] = predictions\n",
    "sub.to_csv('lg006.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grb.predict(test_data)\n",
    "\n",
    " \n",
    "sub['id'] = predictions\n",
    "sub.to_csv('004.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = rf_gs.predict(test_data)\n",
    "\n",
    " \n",
    "sub['id'] = predictions\n",
    "sub.to_csv('rf_gs008.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions4 = dt_auc.predict(test_data)\n",
    "\n",
    " \n",
    "sub['id'] = predictions\n",
    "sub.to_csv('dt_auc.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
